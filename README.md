# Mambaå®‰è£…-åŸºäºmambaæºç è¿›è¡Œcudaç¼–è¯‘
æœ¬ä»“åº“æ—¨åœ¨ä»‹ç»å¦‚ä½•åœ¨Linuxç¯å¢ƒä¸‹é€šè¿‡cudaç¼–è¯‘çš„æ–¹å¼è¿›è¡Œmambaæ¨¡å‹ï¼ˆ[https://github.com/state-spaces/mamba](https://github.com/state-spaces/mamba)ï¼‰çš„å®‰è£…ï¼Œ
å¯è§£å†³selective_scan_cudaåŒ…æ— æ³•æ­£å¸¸ä½¿ç”¨çš„é—®é¢˜ã€‚

Mambaè®ºæ–‡bibtexå¼•ç”¨å¦‚ä¸‹ï¼š
```
@article{mamba,
  title={Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023}
}
```
---
## ç¯å¢ƒè¦æ±‚
- Python >= 3.9 ï¼ˆæœ¬æ¡ˆä¾‹ä½¿ç”¨python-3.10ï¼‰
- CUDA >= 11.6 ï¼ˆæœ¬æ¡ˆä¾‹ä½¿ç”¨CUDA-11.8ï¼‰
- Pytorch >= 1.12.1 ï¼ˆæœ¬æ¡ˆä¾‹ä½¿ç”¨torch-2.3.0ï¼‰
- Linuxï¼ˆæœ¬æ¡ˆä¾‹ä½¿ç”¨Ubuntu-22.0.4ï¼‰
  - è¯·å…ˆç¡®å®šç³»ç»Ÿçš„GLIBCç‰ˆæœ¬å¤§äºç­‰äº2.32ï¼ˆæœ¬æ¡ˆä¾‹ä½¿ç”¨2.35ï¼‰ï¼Œ å¦åˆ™ä¼šå¯¼è‡´pythonæ— æ³•æ­£å¸¸importåŠ¨æ€é“¾æ¥åº“ï¼ˆpython >= 3.7 importåŠ¨æ€é“¾æ¥åº“éœ€è¦ GLIBC >= 2.32ï¼‰ï¼Œ
  å¦‚éœ€æŸ¥çœ‹GLIBCç‰ˆæœ¬å¯ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹ï¼š
  ```shell
  ldd --version
  ```
  - gccï¼Œå…·ä½“ç‰ˆæœ¬è¦æ±‚æœªçŸ¥ï¼Œæœ¬æ–‡ä½¿ç”¨11.4.0
  å¯ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹gccç‰ˆæœ¬
  ```shell
  gcc --version
  ```

# CUDAå®‰è£…
- æœ¬ç« èŠ‚å‚è€ƒåšå®¢ï¼šhttps://www.gongsunqi.xyz/posts/3c995b2a/

é¦–å…ˆéœ€è¦åœ¨ç³»ç»Ÿå±‚é¢è¿›è¡Œå®Œæ•´ç‰ˆCUDAå®‰è£…ï¼ˆcondaå†…ä¹Ÿå¯ä»¥å®‰è£…cudaï¼Œä½†åªæ˜¯ç²¾ç®€ç‰ˆcudaï¼Œæ— æ³•è¿›è¡Œç¼–è¯‘æ“ä½œï¼‰ã€‚
## å®‰è£…CudaToolKit
å…ˆæ‰“å¼€è‹±ä¼Ÿè¾¾CudaToolKitå®˜ç½‘ï¼šhttps://developer.nvidia.com/cuda-toolkit-archive ï¼Œç„¶åé€‰æ‹©cuda11.8ï¼ˆä¹Ÿå¯ä»¥æŒ‰ç…§è‡ªå·±çš„éœ€æ±‚æ¥é€‰æ‹©å…¶ä»–ç‰ˆæœ¬ï¼Œä½†æ˜¯è¦æ±‚å¤§äº11.6ï¼‰
<p align="center">
    <img src="images/cuda_tool_kit_1.png" alt="CudaToolKit-1"/>
</p>
ä¹‹åæŒ‰ç…§è‡ªå·±çš„ç³»ç»Ÿæƒ…å†µè¿›è¡Œé€‰æ‹©ï¼š
<p align="center">
    <img src="images/cuda_tool_kit_2.png" alt="CudaToolKit-2"/>
</p>

- å¦‚æœå½“å‰è´¦æˆ·æœ‰rootæƒé™çš„è¯ï¼ŒInstaller Typeå°±æ­£å¸¸é€‰ç¬¬ä¸€ä¸ªå°±å¥½ï¼Œæ ¹æ®ä¸‹æ–¹ç»™å‡ºçš„æç¤ºè¿›è¡Œå®‰è£…å³å¯ã€‚
``` shell
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda-repo-ubuntu2204-11-8-local_11.8.0-520.61.05-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu2204-11-8-local_11.8.0-520.61.05-1_amd64.deb
sudo cp /var/cuda-repo-ubuntu2204-11-8-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda
```
- å¦‚æœæ²¡æœ‰rootæƒé™çš„è¯ï¼Œå¯ä»¥ä½¿ç”¨ç¬¬ä¸‰é¡¹runfileçš„æ–¹å¼è¿›è¡Œå®‰è£…ï¼Œå…·ä½“å¯ä»¥å‚è€ƒåšå®¢ï¼šhttps://blog.csdn.net/Dove_Dan/article/details/130667793
```shell
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sh cuda_11.8.0_520.61.05_linux.run
```
å®‰è£…æˆåŠŸä»¥åä¿®æ”¹ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœæƒ³ä¿®æ”¹æ‰€æœ‰ç”¨æˆ·å¯ä»¥åœ¨å‰é¢åŠ ä¸Šsudoï¼‰ï¼š
```shell
nano ~/.bashrc
```
ä¹‹åæ·»åŠ ä»¥ä¸‹è·¯å¾„ï¼ˆæ³¨æ„ï¼Œå…·ä½“è·¯å¾„è¯·ä¿®æ”¹ä¸ºè‡ªå·±å®‰è£…è·¯å¾„ï¼Œä»£ç ç¤ºä¾‹ä¸ºé»˜è®¤å®‰è£…è·¯å¾„ï¼‰ï¼š
```
export PATH=/usr/local/cuda-11.8/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:$LD_LIBRARY_PATH
export CUDA_HOME=/usr/local/cuda-11.8
```
æŒ‰ä¸‹ ctrl+x ä¿å­˜åï¼Œè¾“å…¥yä¸¤æ¬¡å›è½¦å³å¯ï¼Œä¹‹åå†æ‰§è¡Œï¼š
```shell
source ~/.bashrc
```
æ¥ä¸‹æ¥å°±å¯ä»¥è¾“å…¥ï¼š
```shell
nvcc -V
```
æŸ¥çœ‹æ˜¯å¦å®‰è£…æˆåŠŸå³å¯ï¼Œæ­£å¸¸åº”è¾“å‡ºå¦‚ä¸‹ä¿¡æ¯ï¼š
```
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2022 NVIDIA Corporation
Built on ä½ çš„å®‰è£…æ—¶é—´
Cuda compilation tools, release 11.8, V11.8.89
Build cuda_11.8.r11.8/compiler.31833905_0
```

## cuDNNå®‰è£…
å…ˆæ‰“å¼€å®˜ç½‘ï¼šhttps://developer.nvidia.com/rdp/cudnn-archive ï¼Œç„¶åé€‰æ‹©å¯¹åº”ç‰ˆæœ¬è¿›è¡Œä¸‹è½½ï¼ˆæœ¬æ¡ˆä¾‹é€‰æ‹©v8.9.7-11.xï¼‰ï¼Œè¿™é‡Œä¸‹è½½éœ€è¦æ³¨å†ŒNVIDIAè´¦å·
<p align="center">
    <img src="images/cuDNN_1.png" alt="cuDNN-1"/>
</p>
ä¹‹åé€‰æ‹©
<p align="center">
    <img src="images/cuDNN_2.png" alt="cuDNN-2"/>
</p>

ç„¶åå°†ä¸‹è½½å¥½çš„å‹ç¼©åŒ…ä¼ åˆ°linuxæœåŠ¡å™¨ä¸­ï¼Œå¹¶åœ¨ç»ˆç«¯cdåˆ°å¯¹åº”ä¸Šä¼ ç›®å½•ï¼Œç„¶åè¿›è¡Œè§£å‹ï¼š
```shell
tar -xvf cudnn**    # **çœç•¥éƒ¨åˆ†æŒ‰tabè‡ªåŠ¨è¡¥å…¨
```
è§£å‹å®Œæˆåcdè¿›è§£å‹æ–‡ä»¶å¤¹ï¼Œç„¶åè¿è¡Œä»¥ä¸‹ä»£ç ï¼ˆå¦‚æœæ²¡æœ‰rootæƒé™ï¼Œcudaå®‰è£…ç›®å½•åº”å½“åœ¨è‡ªå·±è´¦æˆ·ç›®å½•ä¸‹ï¼Œæ­¤æ—¶ä»¥ä¸‹å‘½ä»¤æ— éœ€sudoå‘½ä»¤ï¼‰ï¼š
```shell
sudo cp -r ./lib/* /usr/local/cuda-11.8ï¼ˆæ ¹æ®ä½ çš„cudaå®‰è£…ç›®å½•è¿›è¡Œä¿®æ”¹ï¼‰/lib64/
sudo cp -r ./include/* /usr/local/cuda-11.8ï¼ˆæ ¹æ®ä½ çš„cudaå®‰è£…ç›®å½•è¿›è¡Œä¿®æ”¹ï¼‰/include/
```
æ¥ä¸‹æ¥ä¿®æ”¹æƒé™ï¼š
```shell
sudo chmod a+r /usr/local/cuda-11.8ï¼ˆæ ¹æ®ä½ çš„cudaå®‰è£…ç›®å½•è¿›è¡Œä¿®æ”¹ï¼‰/include/cudnn*
sudo chmod a+r /usr/local/cuda-11.8ï¼ˆæ ¹æ®ä½ çš„cudaå®‰è£…ç›®å½•è¿›è¡Œä¿®æ”¹ï¼‰/lib64/libcudnn*
```
æœ€åæ£€æŸ¥æ˜¯å¦å®‰è£…æˆåŠŸï¼š
```shell
cat /usr/local/cuda-11.8ï¼ˆæ ¹æ®ä½ çš„cudaå®‰è£…ç›®å½•è¿›è¡Œä¿®æ”¹ï¼‰/include/cudnn_version.h | grep CUDNN_MAJOR -A 2
```
æ­£å¸¸åº”è¾“å‡ºä»¥ä¸‹ä¿¡æ¯ï¼š
```
#define CUDNN_MAJOR 8
#define CUDNN_MINOR 9
#define CUDNN_PATCHLEVEL 7
--
#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)

/* cannot use constexpr here since this is a C-only file */
```
è‡³æ­¤ï¼Œcudaå®‰è£…å®Œæˆã€‚

# Mambaå®‰è£…
## Anacondaå®‰è£…ï¼ˆå·²å®‰è£…å¯å¿½ç•¥ï¼‰
è¿™ä¸ªç½‘ä¸Šæ•™ç¨‹ä¸€å¤§å †ï¼Œè¿™é‡Œæˆ‘å°±åªç®€å•è¯´ä¸€ä¸‹ã€‚
é¦–å…ˆä¸‹è½½å®‰è£…ç¨‹åºï¼Œæ–¹æ³•æœ‰å¾ˆå¤šï¼Œä¸‹é¢æä¾›ä¸¤ç§æ–¹æ³•
- å‰å¾€Anacondaå®˜ç½‘ï¼ˆhttps://www.anaconda.com/download ï¼‰é€‰æ‹©linuxç‰ˆæœ¬ï¼Œç›´æ¥ä¸‹è½½
- ç›´æ¥ä½¿ç”¨wgetä¸‹è½½ï¼š
  ```shell
  wget https://repo.anaconda.com/archive/Anaconda3-2024.02-1-Linux-x86_64.sh
  ```
ä¹‹åcdåˆ°ä½ çš„ä¸‹è½½ç›®å½•ï¼Œç›´æ¥æ‰§è¡Œå³å¯ï¼š
```shell
sh Anaconda3-2023.03-Linux-x86_64.sh
```
è¿™é‡Œè®°å¾—æœ€åä¸€æ­¥è¾“å…¥yesåå†å›è½¦ï¼Œç„¶åé‡å¯ç»ˆç«¯å³å¯ã€‚

## Condaç¯å¢ƒåˆ›å»ºå’Œpytorchç¯å¢ƒé…ç½®
å…ˆæ–°å»ºä¸€ä¸ªcondaè™šæ‹Ÿç¯å¢ƒï¼š
```shell
conda create -n mamba-env python=3.10
```
æ¿€æ´»ç¯å¢ƒï¼š
```shell
conda activate mamba-env
```
ç„¶åå®‰è£…pytorchï¼ˆè¿™æ˜¯ä½¿ç”¨pipä¸‹è½½ï¼Œå¦‚éœ€condaä¸‹è½½ã€condaä¸‹è½½æœ€åå¾—åˆ°çš„åŒ…æ–‡ä»¶åä¸ºpytorchï¼Œpipæ˜¯torchã€‘æˆ–è€…å®‰è£…å…¶ä»–ç‰ˆæœ¬ï¼Œå…·ä½“å‘½ä»¤å¯ä»¥å‰å¾€Pytorchå®˜ç½‘ https://pytorch.org/ ï¼‰:
```shell
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

---
### pytorchæ„å»ºå·¥å…·é…ç½®ä¿®æ”¹
å…ˆæŸ¥çœ‹mamba-envç¯å¢ƒè·¯å¾„
```shell
conda env list
```
ç„¶åè¿›å…¥å…·ä½“ç¯å¢ƒè·¯å¾„åï¼Œæ‰“å¼€`ğŸ“ lib`/`ğŸ“ python3.10`/`ğŸ“ site-package`/
`ğŸ“ torch`ï¼ˆcondaä¸‹è½½ä¸ºpytorchï¼Œpipä¸‹è½½ä¸ºtorchï¼‰/`ğŸ“ utils`/`cpp_extension.py`

åœ¨CUDA_GCC_VERSIONSå’ŒMINIMUM_CLANG_VERSIONä¸­æ·»åŠ 11.8çš„ç‰ˆæœ¬ä¿¡æ¯
```python
CUDA_GCC_VERSIONS: VersionMap = {
    '11.0': (MINIMUM_GCC_VERSION, (10, 0)),
    '11.1': (MINIMUM_GCC_VERSION, (11, 0)),
    '11.2': (MINIMUM_GCC_VERSION, (11, 0)),
    '11.3': (MINIMUM_GCC_VERSION, (11, 0)),
    '11.4': ((6, 0, 0), (12, 0)),
    '11.5': ((6, 0, 0), (12, 0)),
    '11.6': ((6, 0, 0), (12, 0)),
    '11.7': ((6, 0, 0), (12, 0)),
    '11.8': ((6, 0, 0), (12, 0)),
}

MINIMUM_CLANG_VERSION = (3, 3, 0)
CUDA_CLANG_VERSIONS: VersionMap = {
    '11.1': (MINIMUM_CLANG_VERSION, (11, 0)),
    '11.2': (MINIMUM_CLANG_VERSION, (12, 0)),
    '11.3': (MINIMUM_CLANG_VERSION, (12, 0)),
    '11.4': (MINIMUM_CLANG_VERSION, (13, 0)),
    '11.5': (MINIMUM_CLANG_VERSION, (13, 0)),
    '11.6': (MINIMUM_CLANG_VERSION, (14, 0)),
    '11.7': (MINIMUM_CLANG_VERSION, (14, 0)),
    '11.8': (MINIMUM_CLANG_VERSION, (14, 0)),
}
```
---

å®‰è£…packagingåŒ…ï¼ˆsetupéœ€è¦ï¼‰ï¼š
```shell
conda install packaging
```

## causal-conv1dç¼–è¯‘å®‰è£…
causal-conv1då…¶å®å¯ä»¥ç”¨pytorchè‡ªå¸¦çš„nn.Conv1dåŠ paddingçš„æ–¹å¼ç­‰ä»·å®ç°ï¼Œä½†æ˜¯æ•ˆç‡ç›¸å¯¹è¾ƒä½ï¼Œcausal-conv1dåº“åœ¨cudaå±‚é¢é‡æ„ï¼Œæ•ˆç‡æ›´é«˜ã€‚
é¦–å…ˆæ‰“å¼€causal-conv1dçš„githubï¼šhttps://github.com/Dao-AILab/causal-conv1d
ç„¶åé€šè¿‡gitæˆ–è€…ç›´æ¥Download Zipæºç çš„æ–¹å¼ä¸‹è½½æºç ï¼Œä¹‹åä¿®æ”¹æºç æ–‡ä»¶å¤¹ä¸­`setup.py`æ–‡ä»¶ï¼Œå°†
```python
# FORCE_BUILD: Force a fresh build locally, instead of attempting to find prebuilt wheels
# SKIP_CUDA_BUILD: Intended to allow CI to use a simple `python setup.py sdist` run to copy over raw files, without any cuda compilation
FORCE_BUILD = os.getenv("CAUSAL_CONV1D_FORCE_BUILD", "FALSE") == "TRUE"
SKIP_CUDA_BUILD = os.getenv("CAUSAL_CONV1D_SKIP_CUDA_BUILD", "FALSE") == "TRUE"
# For CI, we want the option to build with C++11 ABI since the nvcr images use C++11 ABI
FORCE_CXX11_ABI = os.getenv("CAUSAL_CONV1D_FORCE_CXX11_ABI", "FALSE") == "TRUE"
```
ä¿®æ”¹ä¸º
```python
FORCE_BUILD = True
SKIP_CUDA_BUILD = False
FORCE_CXX11_ABI = False
```
å†å°†
```python
cmdclass={"bdist_wheel": CachedWheelsCommand, "build_ext": BuildExtension}
```
ä¿®æ”¹ä¸º
```python
cmdclass={"bdist_wheel": CachedWheelsCommand, 'build_ext': BuildExtension.with_options(use_ninja=False)}
```
æœ€åcdåˆ°causal-conv1dæºç ç›®å½•ä¸‹ï¼Œé€šè¿‡ä»¥ä¸‹å‘½ä»¤è¿›è¡Œå®‰è£…ï¼š
```shell
pip install .
```
å®‰è£…å®Œæˆååœ¨pythonä¸­è¿è¡Œï¼š
```python
import torch
import causal_conv1d_cuda
```
æ²¡æœ‰æŠ¥é”™å³ä¸ºæˆåŠŸã€‚

## mamba-ssmç¼–è¯‘å®‰è£…
mamba-ssmå®‰è£…æµç¨‹å’Œcausal-conv1då®‰è£…æµç¨‹åŸºæœ¬ä¸€è‡´ï¼Œé¦–å…ˆæ‰“å¼€mambaå®˜æ–¹åº“ï¼šhttps://github.com/state-spaces/mamba
ç„¶åé€šè¿‡gitæˆ–è€…ç›´æ¥Download Zipæºç çš„æ–¹å¼ä¸‹è½½æºç ï¼Œä¹‹åä¿®æ”¹æºç æ–‡ä»¶å¤¹ä¸­`setup.py`æ–‡ä»¶ï¼Œå°†
```python
# FORCE_BUILD: Force a fresh build locally, instead of attempting to find prebuilt wheels
# SKIP_CUDA_BUILD: Intended to allow CI to use a simple `python setup.py sdist` run to copy over raw files, without any cuda compilation
FORCE_BUILD = os.getenv("MAMBA_FORCE_BUILD", "FALSE") == "TRUE"
SKIP_CUDA_BUILD = os.getenv("MAMBA_SKIP_CUDA_BUILD", "FALSE") == "TRUE"
# For CI, we want the option to build with C++11 ABI since the nvcr images use C++11 ABI
FORCE_CXX11_ABI = os.getenv("MAMBA_FORCE_CXX11_ABI", "FALSE") == "TRUE"
```
ä¿®æ”¹ä¸º
```python
FORCE_BUILD = True
SKIP_CUDA_BUILD = False
FORCE_CXX11_ABI = False
```
å†å°†
```python
cmdclass={"bdist_wheel": CachedWheelsCommand, "build_ext": BuildExtension}
```
ä¿®æ”¹ä¸º
```python
cmdclass={"bdist_wheel": CachedWheelsCommand, 'build_ext': BuildExtension.with_options(use_ninja=False)}
```
æœ€åcdåˆ°mamba-ssmæºç ç›®å½•ä¸‹ï¼Œé€šè¿‡ä»¥ä¸‹å‘½ä»¤è¿›è¡Œç¼–è¯‘å®‰è£…ï¼š
```shell
pip install .
```
å¦‚éœ€æŸ¥çœ‹ç¼–è¯‘ä¿¡æ¯ï¼Œå¯é€šè¿‡ä»¥ä¸‹å‘½ä»¤ç¼–è¯‘å®‰è£…ï¼š
```shell
pip install . --no-cache-dir --verbose
```
è¿™é‡Œéœ€è¦ä¸‹è½½hugging faceåº“åœ¨å†…çš„å¤§é‡ä¾èµ–åŒ…ï¼Œå¯èƒ½ä¼šå‡ºç°ç½‘è·¯è¶…æ—¶ç­‰é”™è¯¯ï¼Œé‡è¯•å³å¯ã€‚
ä¹‹åç¼–è¯‘æ—¶é—´å¯èƒ½ä¼šè¾ƒä¹…ï¼Œå› ä¸ºmambaçš„cudaé‡å†™äº†ä¸åŒç²¾åº¦çš„å¤šç§ç‰ˆæœ¬ã€‚
å®‰è£…å®Œæˆååœ¨pythonä¸­è¿è¡Œï¼š
```python
import torch
import selective_scan_cuda
```
æ²¡æœ‰æŠ¥é”™å³ä¸ºæˆåŠŸã€‚

# å¼•ç”¨
å¦‚æœè¯¥æ–‡æ¡£ç»™åˆ°ä½ å¸®åŠ©ï¼Œè¯·è€ƒè™‘å¼•ç”¨æˆ‘ä»¬çš„å·¥ä½œğŸ¤—ï¼š
```
@article{fan2024tim4rec,
  title={TiM4Rec: An Efficient Sequential Recommendation Model Based on Time-Aware Structured State Space Duality Model},
  author={Fan, Hao and Zhu, Mengyi and Hu, Yanrong and Feng, Hailin and He, Zhijie and Liu, Hongjiu and Liu, Qingyang},
  journal={arXiv preprint arXiv:2409.16182},
  year={2024}
}
```